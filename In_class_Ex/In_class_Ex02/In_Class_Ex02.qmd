---
title: "In-Class Exercise 2"
date: "25 November 2023"
date-modified: "last-modified"
format: html
execute: 
  echo: true # all code chunks will appear
  eval: true # all code chunks will run live
  warning: false # do not display warning message
editor: visual
---

# Getting Started
We will use the following packages in this in-class exercise:
```{r}
pacman::p_load(sf, tmap, sfdep, tidyverse, knitr, plotly)
```

# Loading the Data

First, we will import Hunan, a geospatial data set in ESRI shapefile format:
```{r}
hunan <- st_read(dsn = "data/geospatial",
                 layer = "Hunan")
```

Next, we will import Hunan_2012, an attribute data set in csv file:
```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```
We will combine hunan and hunan2012 using left_join():
```{r}
hunan_GDPPC <- left_join(hunan, hunan2012) %>%
  select(1:4,7,15)
```
Use left join to retain the geometry of the shapefile and to retain the sf data frame output format. 


# Deriving Contiguity Spatial Weights: Queen's Method
We will use the following code to derive contiguity weights using Qeen's method.


```{r}
wm_q <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb, style = "W"),
         .before = 1)
```

# Computing Local Moran's I
We will use the following code to compute Local Moran's I on GDPCC at the county level, using the local_moran() function from sfdep.

```{r}
lisa <- wm_q %>%
  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)
```

the output of local_moran() is a sf data frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.

unnest() is used to split the values into columns.

sfdep helps to  compute the low-low, low-high, high-low, and high-high by mean, median and pysal. If distribution is skewed, we should use median. Otherwise, we can use mean. 

## Visualising Local Moran's I







```{r}
pacman::p_load(sf, tmap, sfdep, tidyverse, knitr, plotly)
```

```{r}
GDPPC <- read.csv("data/aspatial/Hunan_GDPPC.csv")
```


```{r}
GDPPC_st <- spacetime(GDPPC, hunan,
                      .loc_col = "County",
                      .time_col = "Year")
```

```{r}
GDPPC_nb <- GDPPC_st %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),
         .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")
```


```{r}
# gi_stars <- GDPPC_nb %>%
  #group_by(Year) %>%
  #mutate(gi_star = local_gstar_perm(GDPPC, nb, wt)) %>%
  #tidyr::unnest(gi_star)
```

```{r}
ggplot(data = )
```



# Emerging Hot Spot Analysis

```{r}
ehsa <- emerging_hotspot_analysis(
  x = GDPPC_st, 
  .var = "GDPPC",
  k = 1, 
  nsim = 99
)
```








 






























































