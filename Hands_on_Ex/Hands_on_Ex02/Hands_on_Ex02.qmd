---
title: "Hands-on Exercise 2"
date: "21 November 2023"
date-modified: "last-modified"
format: html
execute: 
  echo: true # all code chunks will appear
  eval: true # all code chunks will run live
  warning: false # do not display warning message
editor: visual
---

# Overview

This is the second hands-on exercise for ISSS624 Applied Geospatial Analytics.

# 1. Spatial Weights and Applications

## 1.1. Data and Study Area

Two data sets will be used in this exercise:

1.  Hunan county boundary layer: geospatial data set in ESRI shapefile format.

2.  Hunan_2012.csv: Hunan's local development indicators in 2012.

The following R packages will be imported and used in this exercise:

1.  sf package to import geospatial data

2.  readr package to import csv files

3.  dplyr package to perform relational join function

4.  spdep package to compute spatial weights and spatially lagged variables

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
```

## 1.2. Importing Data

### 1.2.1. Importing Geospatial Data

The following code imports the shapefile into R using the `st_read()` function from the `sf` package:

```{r}
hunan <- st_read(dsn = "data/geospatial",
                 layer = "Hunan")
```

### 1.2.2. Importing Attribute Data

The following code imports the csv file into R using `read_csv()` function from the `readr` package:

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

### 1.2.3. Performing Relational Join

The following code joins the attribute table of Hunan's SpatialPolygonsDataFrame with the attribute fields of the hunan2012 data frame using the `left_join()` function from the `dplyr` package:

```{r}
hunan <- left_join(hunan, hunan2012) %>%
  select(1:4,7,15)
```

## 1.3. Visualising Regional Development Indicator

We will now prepare a base map and a choropleth map to show the distribution of GDPPC 2012 by using the `qtm()` function from the `tmap` package:

```{r}
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size = 0.4)

gdppc <- qtm(hunan,"GDPPC")
```

```{r}
tmap_arrange(basemap, gdppc, asp = 1, ncol = 2)
```

## 1.4. Computing Contiguity Spatial Weights

The `poly2nb()` function from the `spdep` package will be used to compute contiguity weight matrices for the study area. This function builds a list of neighbours based on regions with contiguous boundaries.

The default `queen` argument is `TRUE`, which will return a list of first order neighbours using the queen criteria.

### 1.4.1. Computing Contiguity-based Neighbours (`Queen`)

This code is used to compute the `queen` contiguity weight matrix:

```{r}
wm_q <- poly2nb(hunan, queen = TRUE)
summary(wm_q)
```

The summary report shows that there are 88 regions in Hunan; the most connected region has 11 neighbours while there are only two regions with one neighbour.

For each polygon in the polygon object, `wm_q` lists all neighbouring polygons. We can view the neighbours of a specific polygon object using the following code:

```{r}
wm_q[[1]]
```

The output shows that polygon ID 1 has five neighbours, and the numbers shown represent the polygon IDs stored in the data frame.

We can retrieve the county name of polygon ID 1:

```{r}
hunan$County[1]
```

Which shows that polygon ID 1 is Anxiang County.

To reveal the county names of all neighbouring counties:

```{r}
hunan$NAME_3[c(wm_q[[1]])]
```

We can retrieve the GDPPC of the counties by using the following code:

```{r}
hunan$GDPPC[wm_q[[1]]]
```

The printed output shows that the GDPPC of the five nearest neighbours of County ID 1 based on Queen's method are 20981, 34592, 24473, 21311, and 22879 respectively.

The complete weight matrix can be displayed using the str() function:

```{r}
str(wm_q)
```

### 1.4.2. Creating Contiguity-based Neighbours (Rook)

This code is used to compute the `rook`contiguity weight matrix:

```{r}
wm_r <- poly2nb(hunan, queen = FALSE)
summary(wm_r)
```

The summary report shows that there are 88 regions in Hunan; the most connected region has 10 neighbours while there are only two regions with one neighbour.

### 1.4.3. Visualising Contiguity Weights

Contiguity weights can be visualised using a connectivity graph, which takes a point and draws lines to each neighbouring point. As an intermediary step, points have to be derived from the polygons in the current data set.

The coordinates of each point have to be stored in a separate data frame using a mapping function to map a function to each element of a vector and return a vector of the same length. The input vector will be the geometry column of us.bound, the st_centroid() function will be used with the map_dbl() variation from the purrr package.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

> The longitude value is accessed through double brackets \[\[\]\] and 1 as longitude is the first value in each centroid.

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

> The latitude value is accessed through double brackets \[\[\]\] and 2 as latitude is the second value in each centroid.

```{r}
coords <- cbind(longitude, latitude)
```

To check that longitude and latitude are formatted correctly:

```{r}
head(coords)
```

We will now plot the Queen contiguity-based neighbours map:

```{r}
plot(hunan$geometry, border = "lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

Next, we will plot the Rook contiguity-based neighbours map:

```{r}
plot(hunan$geometry, border = "lightgrey")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

Then, we will plot both Queen and Rook contiguity-based neighbours map together:

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border = "lightgrey", main = "Queen Contiguity")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
plot(hunan$geometry, border = "lightgrey", main = "Rook Contiguity")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## 1.5. Computing Distance-based Neighbours

In this section, distance-based weight matrices will be derived using the dnearneigh() function from the spdep package.

The function identifies neighbours of region points by Euclidean distance bound by the lower d1= and the upper d2= range.

### 1.5.1. Determine the Cut-off Distance

The cut-off distance can be determined using the following code:

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest and nearest neighbour distance is 61.79km. Hence, using this as the upper threshold ensures that all units will have at least one neighbour.

### 1.5.2. Computing Fixed Distance Weight Matrix

We will now compute the distance weight matrix by using the dnearneigh() function:

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

The output shows that there are 88 regions and that on average, each point is connected to 3.68 neighbours.

Next, we will use `str()` to display the content of the `wm_d62` weight matrix:

```{r}
str(wm_d62)
```

We can also display the content of the `wm_d62` weight matrix using `table()` and `card()`:

```{r}
table(hunan$County, card(wm_d62))
```

#### 1.5.2.1. Plotting Fixed Distance Weight Matrix

We will use the following code to plot the distance weight matrix:

```{r}
plot(hunan$geometry, border = 'lightgrey')
plot(wm_d62, coords, add = TRUE)
plot(k1, coords, add = TRUE, col = 'red', length = 0.08)
```

The red line shows the links of the first nearest neighbours and the black line shows the links of neighbours within a cut-off distance of 62km.

We can plot both maps next to each other for comparison:

```{r}
par(mfrow = c(1,2))
plot(hunan$geometry, border = 'lightgrey', main = "First nearest neighbours")
plot(k1, coords, add = TRUE, col = 'red', length = 0.08)
plot(hunan$geometry, border = 'lightgrey', main = 'Distance link')
plot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6)
```

### 1.5.3. Computing Adaptive Distance Weight Matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas tend to have more neighbours while less densely settled areas tend to have less neighbours. Having many neighbours smooths the neighbour relationship across more neighbours.

The number of neighbours can be controlled using k-nearest neighbours, through either accepting asymmetric neighbours or imposing symmetry as shown in the code below:

```{r}
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```

We can display the content of the matrix using `str()`:

```{r}
str(knn6)
```

#### 1.5.3.1. Plotting Distance-based Neighbours

We can plot the weight matrix using the following code:

```{r}
plot(hunan$geometry, border = 'lightgrey')
plot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## 1.6. Weights Based On Inversed Distance Weighting

Spatial weights can be derived based on Inversed Distance Weighting (IDW).

First, the distances between areas are computed using `nbdist()` from `spdep`.

```{r}
dist <- nbdists(wm_q, coords, longlat = TRUE)
ids <- lapply(dist, function(x) 1/(x))
ids
```

### 1.6.1. Row-standardised Weights Matrix

For this exercise, we will assign equal weight (`style = "W"`) by assigning 1/(# neighbours) to each neighbouring county before summing the weighted income values. However, the polygons along the edges of the study are will base their lagged values on fewer polygons, which might potentially over- or under-estimate the true nature of spatial autocorrelation in the data. Other more robust options such as `style = "B"` will be more robust.

```{r}
rswm_q <- nb2listw(wm_q, style = "W", zero.policy = TRUE)
rswm_q
```

When `zero.policy = TRUE`, weights vectors of zero length are inserted for regions without neighbours in the neighbours list. These will then generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length = length(neighbours))) %\>% x for arbitrary numerical vector x of length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero.

style can take the following values: "W" for equal weight "B" for basic binary coding "C" for globally standardised (sums over all links to n) "U" for "C" divided by number of neighbours (sums over all links to unity) "S" for variance-standardising coding scheme (sums over all links to n)

To see the weight of the first polygon's eight neighbours:

```{r}
rswm_q$weights[10]
```

It is observed that each neighbour is assigned 0.125 of the total weight.

Using the same method, we can derive a row standardised distance weight by using this code:

```{r}
rswm_ids <- nb2listw(wm_q, glist = ids, style = "B", zero.policy = TRUE)
rswm_ids
```

```{r}
rswm_ids$weights[1]
```

```{r}
summary(unlist(rswm_ids$weights))
```

## 1.7. Applications of Spatial Weight Matrix

We will learn four different spatial lagged variables in this section:

1.  Spatial lag with row-standardised weights

2.  Spatial lag as a sum of neighbouring values

3.  Spatial window average

4.  Spatial window sum

### 1.7.1. Spatial Lag with Row-standardised Weights

We will compute the average neighbour GDPPC value for each polygon. These values are referred to as spatially lagged values.

```{r}
GDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)
GDPPC.lag
```

We can append the spatially lag GDPPC values to the hunan sf data frame using the following code:

```{r}
lag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))
lag.res <- as.data.frame(lag.list)
colnames(lag.res) <- c("NAME_3","lag_GDPPC")
hunan <- left_join(hunan, lag.res)
```

```{r}
head(hunan)
```

Next, we will plot the GDPPC and spatial lag GDPPC for comparison:

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_gdppc <- qtm(hunan, "lag_GDPPC")
tmap_arrange(gdppc, lag_gdppc, asp = 1, ncol = 2)
```

### 1.7.2. Spatial Lag as Sum of Neighbouring Values

We can calculate spatial lag as a sum of neighbouring values by assigning binary weights. This requires a function to assign binary weights to be applied to the neighbours list before using `glist =` from the `nb2listw` function to assign these weights.

We start by using `lapply` to assign a value of 1 to each neighbour. `lapply` applies a function across each value in the neighbours structure.

```{r}
b_weights <- lapply(wm_q, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_q, glist = b_weights, style = "B")
b_weights2
```

Next, we use `lag.listw()` to compute a lag variable from the weight and GDPPC:

```{r}
lag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
lag.res <- as.data.frame(lag_sum)
colnames(lag.res) <- c("NAME_3", "lag_sum GDPPC")
lag.res
```

Next, we will append the `lag_sum GDPPC` field into `hunan` sf data frame:

```{r}
hunan <- left_join(hunan, lag.res)
```

Now we will plot the gdppc and spatial lag sum gdppc for comparison:

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_sum_gdppc <- qtm(hunan, "lag_sum GDPPC")
tmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)
```

### 1.7.3. Spatial Window Average

The spatial window average uses row-standardised weights and includes the diagonal elements. We will add the diagonal element to the neighbours structures before assignign weights,

This is done with the `include.self()` function from `spdep`:

```{r}
wm_qs <- include.self(wm_q)
summary(wm_qs)
```

It is observed that the number of nonzero links, percentage of nonzero weights and average number of links are higher than that of wm_q.

We will now examine the neighbour list of area\[1\] using the following code:

```{r}
wm_qs[[1]]
```

Polygon ID 1 now has six neighbours instead of five.

We can use the following code to obtain the weights:

```{r}
wm_qs <- nb2listw(wm_qs)
wm_qs
```

We will now use `nb2listw()` and `glist()` to explitcitly assign weight values and create the lag variable.

```{r}
lag_avg_gdppc <- lag.listw(wm_qs, hunan$GDPPC)
lag_avg_gdppc
```

We will convert the lag variable `listw` object into a data frame:

```{r}
lag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))
lag_wm_qs.res <- as.data.frame(lag.list.wm_qs)
colnames(lag_wm_qs.res) <- c("NAME_3", "lag_window_avg GDPPC")
```

We will join the lag_window_ave GDPPC values with the hunan sf data frame:

```{r}
hunan <- left_join(hunan, lag_wm_qs.res)
```

We can use `kable()` to prepare a table to compare the values of lag GDPPC and spatial window average:

```{r}
hunan %>%
  select("County",
         "lag_GDPPC",
         "lag_window_avg GDPPC") %>%
  kable()
```

Lastly, we can plot the `lag_gdppc` and `w_avg_gdppc` for comparison:

```{r}
w_avg_gdppc <- qtm(hunan, "lag_window_avg GDPPC")
tmap_arrange(lag_gdppc, w_avg_gdppc, asp = 1, ncol = 2)
```

### 1.7.4. Spatial Window Sum

The spatial window sum is the counterpart of the window average without using row-standardised weights.

First, we have to add diagonal elements to the neighbour list:

```{r}
wm_qs <- include.self(wm_q)
wm_qs
```

Next, we will assign binary weights to the neighbour structure to include the diagonal elements:

```{r}
b_weights <- lapply(wm_qs, function(x) 0*x + 1)
b_weights[1]
```

It is observed that Polygon ID 1 has six neighbours now instead of five.

Next, we will use `nb2listw()` and `glist()` to explicitly assign weight values:

```{r}
b_weights2 <- nb2listw(wm_qs, glist = b_weights, style = "B")
b_weights2
```

Next, we will compute the lag variable using `lag.listw()`:

```{r}
w_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
w_sum_gdppc
```

Next, we will convert the lag variable `listw` object to a data frame:

```{r}
w_sum_gdppc.res <- as.data.frame(w_sum_gdppc)
colnames(w_sum_gdppc.res) <- c("NAME_3", "w_sum GDPPC")
```

Next, we will append the `w_sum_gdppc` values ot the `hunan` sf data frame:

```{r}
hunan <- left_join(hunan, w_sum_gdppc.res)
```

We can use `kable()` to prepare a table to compare the values of lag GDPPC and spatial window sum:

```{r}
hunan %>%
  select("County", "lag_sum GDPPC", "w_sum GDPPC") %>%
  kable()
```

Lastly, we can plot the `lag_gdppc` and `w_sum_gdppc` for comparison:

```{r}
w_sum_gdppc <- qtm(hunan, "w_sum GDPPC")
tmap_arrange(lag_gdppc, w_sum_gdppc, asp = 1, ncol = 2)
```

# 2. Global Measures of Spatial Autocorrelation

## 2.1. Overview

In spatial policy, one of the main development objectives of local government and planners is to ensure equal distribution of development in the province. We will apply appropriate spatial statistical methods to discover if development is evenly distributed geographically. This will be a case study of the spatial pattern of **GDP Per Capita** in Hunan Province, China.

The same data sets and R packages imported from section 1 will be used.

## 2.2. Visualising Regional Development Indicator

We will create a basemap and choropleth map to show the distribution of GDPPC 2012 by using `qtm()` from the `tmap` package:

```{r}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC", n = 5, style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal Interval Classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC", n = 5, style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal Quantile Classification")

tmap_arrange(equal, quantile, asp = 1, ncol = 2)
```

## 2.3. Global Spatial Autocorrelation

In this section, we will compute gloabl spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation. We will use the contiguity spatial weights and row-standardised weights matrix computed in the previous section to perform the required statistical tests.

### 2.3.1. Global Spatial Autocorrelation: Moran's I

We will perform **Moran's I** statistics test using `moran.test()` from `spdep`.

```{r}
moran.test(hunan$GDPPC, listw = rswm_q, zero.policy = TRUE,
           na.action = na.omit)
```

The p-value from the test = 1.095e-06, which signifies that the null hypothesis is rejected at 5% alpha. This means that the spatial distribution of high values and/or low values in the data set is more spatially clustered than would be expected if underlying spatial processes were random.

#### 2.3.1.1. Computing Monte Carlo Moran's I

We will use the following code to perform permutation test for **Moran's I** statistic using `moran.mc()` from `spdep`. 1000 simulations will be performed.

```{r}
set.seed(1234)
bperm_I <- moran.mc(hunan$GDPPC, listw = rswm_q, nsim = 999, 
                  zero.policy = TRUE, na.action = na.omit)
bperm_I
```

Using 1000 simulations, the Moran I statistic remains stable at around 0.30075. The p-value from the 1000 simulations = 0.001, which signifies that the null hypothesis is rejected at 5% alpha. This means that the spatial distribution of high values and/or low values in the data set is more spatially clustered than would be expected if underlying spatial processes were random.

#### 2.3.1.2. Visualising Monte Carlo Moran's I

The following code can be used to visualise the Moran's I test statistics in greater detail through a histogram:

```{r}
mean(bperm_I$res[1:999])
```

```{r}
var(bperm_I$res[1:999])
```

```{r}
summary(bperm_I$res[1:999])
```

```{r}
hist(bperm_I$res, freq = TRUE, breaks = 20, xlab = "Simulated Moran's I")
abline(v = 0, col = 'red')
```

It can be observed that the distribution of `bperm_I$res` resembles the shape of a normal distribution.

### 2.3.2. Global Spatial Autocorrelation: Geary's

We will perform **Geary's c** statistics test using `geary.test()` from `spdep`.

```{r}
geary.test(hunan$GDPPC, listw = rswm_q)
```

The p-value from the test = 0.0001526, which signifies that the null hypothesis is rejected at 5% alpha. This means that the expectation of spatial distribution is greater than the statistic.

#### 2.3.2.1. Computing Monte Geary's C

We will use the following code to perform permutation test for **Geary's c** statistic using `geary.mc()` from spdep. 1000 simulations will be performed.

```{r}
set.seed(1234)
bperm_c <- geary.mc(hunan$GDPPC, listw = rswm_q, nsim = 999, 
                  zero.policy = TRUE)
bperm_c
```

Using 1000 simulations, the Geary's c statistic remains stable at around 0.69072. The p-value from the 1000 simulations = 0.001, which signifies that the null hypothesis is rejected at 5% alpha. This means that the expectation of spatial distribution is greater than the statistic.

#### 2.3.2.2. Visualising Monte Carlo Geary's C

The following code can be used to visualise the Geary's c test statistics in greater detail through a histogram:

```{r}
mean(bperm_c$res[1:999])
```

```{r}
var(bperm_c$res[1:999])
```

```{r}
summary(bperm_c$res[1:999])
```

```{r}
hist(bperm_c$res, freq = TRUE, breaks = 20, xlab = "Simulated Moran's I")
abline(v = 1, col = 'red')
```

It can be observed that the distribution of `bperm_c$res` resembles the shape of a normal distribution.

## 2.4. Spatial Correlogram

Spatial correlograms help to examine patterns of spatial autocorrelation in the data or model residuals. They show the extent of correlation between pairs of spatial observations when distance (lag) is increased between them. Correlograms are useful as an exploratory and descriptive tool.

### 2.4.1. Compute Moran's I Correlogram

We will use `sp.correlogram()` from `spdep` to compute a 6-lag spatial correlogram of GDPPC.

```{r}
MI_corr <-sp.correlogram(wm_q, hunan$GDPPC, order = 6,
                         method = "I", style = "W")
plot(MI_corr)
```

Not all autocorrelation values are statistically significant, and this is not visible from the plot above. We will examine the full analysis report for a closer look:

```{r}
print(MI_corr)
```

It can be observed from the plot that there is a downward trend in the autocorrelation as lag increases. From the output of the analysis report, it is observed that the autocorrelation when lag = 5 is not significant at alpha 5% as the p-value = 0.226015.

### 2.4.2. Compute Geary's C Correlogram

We will use `sp.correlogram()` from `spdep` to compute a 6-lag spatial correlogram of GDPPC.

```{r}
GC_corr <-sp.correlogram(wm_q, hunan$GDPPC, order = 6,
                         method = "C", style = "W")
plot(GC_corr)
```

Not all autocorrelation values are statistically significant, and this is not visible from the plot above. We will examine the full analysis report for a closer look:

```{r}
print(GC_corr)
```

It can be observed from the plot that there is a upward trend in the autocorrelation as lag increases. From the output of the analysis report, it is observed that the autocorrelation when lag = 3, 4, and 6 is not significant at alpha 5% as the respective p-values are greater than 0.05.

## 2.5. Cluster and Outlier Analysis

Local Indicators of Spatial Association (LISA) evaluates the existence of clusters in the spatial arrangement of a given variable. We will apply the appropriate LISA methods to detect cluster and/or outlier from GDP Per Capita 2012 of Hunan Province.

### 2.5.1. Computing Local Moran's I

We will use the localmoran() function from spdep to compute local Moran's I. This function computes Ii values given a set of zi values and listw object project neighbour weight information of the polygons associated with the zi values.

The following code computes local Moran's I at the county level:

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

The localmoran() function returns a matrix of values with the following columns:

-   `Ii`: the local Moran's I statistics

-   `E.Ii`: the expected local Moran statistics under randomisation hypothesis

-   `Var.Ii`: the variance of local Moran statistics under randomisation hypothesis

-   `Z.Li`: the standard deviate of local Moran statistic

-   `Pr()`: the p-value of local Moran statistic

We will use the following code to list the content of the local Moran matrix:

```{r}
printCoefmat(data.frame(
  localMI[fips,],
  row.names = hunan$County[fips]),
  check.names = FALSE)
```

#### 2.5.1.1. Mapping Local Moran's I

The local Moran's I data frame is first appended to the hunan `SpatialPolygonDataFrame`:

```{r}
hunan.localMI <- cbind(hunan, localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

We will use the following code to plot a choropleth map of Moran I's values:

```{r}
tm_shape(hunan.localMI) + 
  tm_fill(col = "Ii",
          style = "pretty",
          palette = "RdBu",
          title = "Local Moran Statistics") +
  tm_borders(alpha = 0.5)
```

We will use the following code to plot a choropleth map of Moran I's p-values:

```{r}
tm_shape(hunan.localMI) + 
  tm_fill(col = "Pr.Ii",
          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette = "-Blues",
          title = "Local Moran p-values") +
  tm_borders(alpha = 0.5)
```

Both maps can be plotted together for easier comparison and interpretation:

```{r}
localMI_map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii",
          style = "pretty",
          palette = "RdBu",
          title = "Local Moran Statistics") +
  tm_borders(alpha = 0.5)

pvalue_map <- tm_shape(hunan.localMI) + 
  tm_fill(col = "Pr.Ii",
          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette = "-Blues",
          title = "Local Moran p-values") +
  tm_borders(alpha = 0.5)
tmap_arrange(localMI_map, pvalue_map, asp =1, ncol = 2)
```

## 2.6. Creating a LISA Cluster Map

The LISA cluster map shows the significant locations colour coded by the type of spatial autocorrelation. First, we have to plot the Moran scatterplot.

### 2.6.1. Plotting Moran Scatterplot

The Moran scatterplot illustrates the relationship between the values of a chosen attribute at each location and the average value of the same attribute at neighbouring locations. This is done using the following code:

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q, 
                  labels = as.character(hunan$County),
                  xlab = "GDPPC 2012",
                  ylab = "Spatially Lag GDPPC 2012")
```

The plot is split into four quadrants. The top corner belongs to areas with high GDPPC and are surrounded by other areas with average levels of GDPPC.

### 2.6.2. Plotting Moran Scatterplot with Standardised Variables

We will use the scale() function to center and scale the variable. Centering is done by subtracting the mean from the corresponding columns while scaling is done by dividing the centered variable by their standard deviations:

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>%
  as.vector
```

> Using `as.vector` at the end ensures that the data output is in vector format.

We will plot the Moran scatterplot again using the standardised variables:

```{r}
nci2 <- moran.plot(hunan$GDPPC, rswm_q,
                   labels = as.character(hunan$County),
                   xlab = "z-GDPPC 2012",
                   ylab = "Spatially Lag z-GDPPC 2012")
```

### 2.6.3. Preparing LISA Map Classes

We will use the following code to prepare a LISA cluster map:

```{r}
quadrant <- vector(mode = "numeric", length = nrow(localMI))
```

We will now derive the spatially lagged variable and center it around its mean.

```{r}
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)
```

The local Moran's is centered around its mean:

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])
```

We will set a significance level for the local Moran:

```{r}
signif <- 0.05
```

We will define the low-low (1), low-high (2), high-low (3), and high-high (4) categories:

```{r}
quadrant[DV < 0 & LM_I > 0] <- 1
quadrant[DV > 0 & LM_I < 0] <- 2
quadrant[DV < 0 & LM_I < 0] <- 3
quadrant[DV > 0 & LM_I > 0] <- 4
quadrant[localMI[,5] > signif] <- 0
```

### 2.6.4. Plotting LISA Map

We will build the LISA map using the following code:

```{r}
hunan.localMI$quadrant  <- quadrant 
colours <- c('#ffffff', '#2c7bb6', '#abd9e9', '#fdae61', '#d7191c')
clusters <- c('insignificant', 'low-low', 'low-high', 'high-low', 'high-high')

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant",
          style = 'cat',
          palette = colours[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha = 0.5)
```

We can plot both the local Moran's I values map together with the p-values map:

```{r}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colours <- c('#ffffff', '#2c7bb6', '#abd9e9', '#fdae61', '#d7191c')
clusters <- c('insignificant', 'low-low', 'low-high', 'high-low', 'high-high')

LISA_map <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant",
          style = 'cat',
          palette = colours[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, LISA_map, asp = 1, ncol = 2)
```

## 2.7. Hot Spot and Cold Spot Area Analysis

Besides detecting cluster and outliers, localised spatial statistics can be used to detect hot spot and/or cold spot areas. The term 'hot spot' has been used generally to describe a region or value that is higher than its surroundings.

### 2.7.1. Getis and Ord's G-Statistics

An alternative spatial statistics to detect spatial anomalies is the Getis and Ord's G-statistics. It looks at neighbours within a defined proximity to identify where the high or low values cluster spatially. Statistically significant hot spots are recognised as areas of high values where other areas within a neighbourhood range also share high values.

### 2.7.2. Deriving Distance-based Weight Matrix

First, we need to define a new set of neighbours as the Getis-Ord defines neighbours based on distance.

We can derive the centroid or cut-off distance.

#### 2.7.2.1. Deriving Centroid

To get the longitude and latitude values, we map `st_centroid()` over the geometry column of us.bound and access each value through \[\[\]\] and 1 and 2 respectively.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])

latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])

coords <- cbind(longitude, latitude)
```

#### 2.7.2.2. Determine Cut-off Distance

We will determine the upper limit for the distance band, which is 61.79km.

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

#### 2.7.2.3. Computing Fixed Distance Weight Matrix

We will compute the distance weight matrix using `dnearneigh()`:

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Next, we will use `nb2listw()` to convert the nb object into spatial weights object:

```{r}
wm62_lw <- nb2listw(wm_d62, style = "B")
summary(wm62_lw)
```

### 2.7.3 Computing Adaptive Distance Weight Matrix

One of the characteristics of fixed distance weight matrix is that more densely populated areas tend to have more neighbours while less densely populated areas tend to have less neighbours.

We can use k-nearest neighbours to control the number of neighbours by accepting assymetric neighbours or by imposing symmetry:

```{r}
knn <- knn2nb(knearneigh(coords, k = 8))
knn
```

Next, we will use `nb2listw()` to convert the nb object into spatial weights object:

```{r}
knn_lw <- nb2listw(knn, style = "B")
```

## 2.8. Computing Gi Statistics

### 2.8.1. Computing Gi Statistics using Fixed Distance

```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

The output of localG() is a vector of G or Gstar values. We can see that gstari is FALSE and "call" is set to the function call and "class" is "localG"

The Gi statistics is represented as a Z-score. Bigger values represent a bigger intensity of clustering and the direction (positive or negative) indicates high or low clusters.

Next, we will join the Gi values to the corresponding hunan sf data frame:

```{r}
hunan.gi.f <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

#### 2.8.1.1. Mapping Gi Values with Fixed Distance Weights

We will use the following code to map the Gi values with fixed distance weights:

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gi_f_map <- tm_shape(hunan.gi.f) +
  tm_fill(col = "gstat_fixed",
          style = "pretty",
          palette = "-RdBu",
          title = 'Local Gi (Fixed)') +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gi_f_map, asp = 1, ncol = 2)
```

### 2.8.2. Gi Statistics Using Adaptive Distance Weights

We will use the following code to map the Gi values using adaptive distance weights:

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi.a <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

#### 2.8.2.1. Mapping Gi Values with Adaptive Distance Weights

We will use the following code to map the Gi values with adaptive distance weights:

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gi_a_map <- tm_shape(hunan.gi.a) +
  tm_fill(col = "gstat_adaptive",
          style = "pretty",
          palette = "-RdBu",
          title = "Local Gi (Adaptive)") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gi_a_map, asp = 1, ncol = 2)
```
